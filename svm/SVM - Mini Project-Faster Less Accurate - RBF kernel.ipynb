{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author ID Accuracy\n",
    "+ Create and train a SVM classifier in naive_bayes/svm_author_id.py\n",
    "+ Use it to make predictions for the test set\n",
    "+ What is the accuracy?\n",
    "\n",
    "> + When training you may see the following error: UserWarning: Duplicate scores\n",
    "+ Result may depend on feature ordering\n",
    "+ There are probably duplicate features, or you used a classification score for a regression task\n",
    "+ warn(\"Duplicate scores. Result may depend on feature ordering.\")\n",
    "\n",
    "+ This is a warning that two or more words happen to have the same usage patterns in the emails--as far as the algorithm is concerned, this means that two features are the same\n",
    "+ Some algorithms will actually break (mathematically wonâ€™t work) or give multiple different answers (depending on feature ordering) when there are duplicate features and sklearn is giving us a warning\n",
    "+ Good information, but not something we have to worry about\n",
    "\n",
    "### This is the code to accompany the Lesson 1 (Naive Bayes) mini-project. \n",
    "\n",
    "**Use a Naive Bayes Classifier to identify emails by their authors**\n",
    "```\n",
    "        authors and labels:\n",
    "        Sara has label 0\n",
    "        Chris has label 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\IntelPython3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#import cPickle # http://bit.ly/2ibKHa3\n",
    "import _pickle as cPickle\n",
    "import numpy\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "def preprocess(words_file = \"../tools/word_data.pkl\", authors_file=\"../tools/email_authors.pkl\"):\n",
    "    \"\"\" \n",
    "        this function takes a pre-made list of email texts (by default word_data.pkl)\n",
    "        and the corresponding authors (by default email_authors.pkl) and performs\n",
    "        a number of preprocessing steps:\n",
    "            -- splits into training/testing sets (10% testing)\n",
    "            -- vectorizes into tfidf matrix\n",
    "            -- selects/keeps most helpful features\n",
    "\n",
    "        after this, the feaures and labels are put into numpy arrays, which play nice with sklearn functions\n",
    "\n",
    "        4 objects are returned:\n",
    "            -- training/testing features\n",
    "            -- training/testing labels\n",
    "\n",
    "    \"\"\"\n",
    "    ### the words (features) and authors (labels), already largely preprocessed\n",
    "    ### this preprocessing will be repeated in the text learning mini-project\n",
    "    authors_file_handler = open(authors_file, \"rb\")\n",
    "    authors = pickle.load(authors_file_handler)\n",
    "    authors_file_handler.close()\n",
    "\n",
    "    words_file_handler = open(words_file, \"rb\")\n",
    "    word_data = cPickle.load(words_file_handler)\n",
    "    words_file_handler.close()\n",
    "    ### test_size is the percentage of events assigned to the test set\n",
    "    ### (remainder go into training)\n",
    "    features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
    "    ### text vectorization--go from strings to lists of numbers\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "    features_test_transformed  = vectorizer.transform(features_test)\n",
    "    ### feature selection, because text is super high dimensional and \n",
    "    ### can be really computationally chewy as a result\n",
    "    selector = SelectPercentile(f_classif, percentile=10)\n",
    "    selector.fit(features_train_transformed, labels_train)\n",
    "    features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
    "    features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
    "    ### info on the data\n",
    "    print(\"no. of Chris training emails:\", sum(labels_train))\n",
    "    print(\"no. of Sara training emails :\" , len(labels_train)-sum(labels_train))\n",
    "    \n",
    "    return features_train_transformed, features_test_transformed, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails : 7884\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#+--------------------------------------------------------------------+\n",
    "#| 'features_train' are the features for the training                 |\n",
    "#| 'features_test' are the testing datasets                           |\n",
    "#| \"labels_train\" and \"labels_test\" are the corresponding item labels |\n",
    "#+--------------------------------------------------------------------+\n",
    "def NBAccuracy(features_train, labels_train, features_test, labels_test):\n",
    "    from time import time\n",
    "    \"\"\" Compute the accuracy of your Naive Bayes classifier \"\"\"\n",
    "    ### import the sklearn module for GaussianNB\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics     import accuracy_score\n",
    "    ### create classifier\n",
    "    clf = SVC(kernel='linear')\n",
    "    ### Reduce size of data sets, to speed up trainning\n",
    "    features_train = features_train[:int(len(features_train)/100)]\n",
    "    labels_train = labels_train[:int(len(labels_train)/100)]\n",
    "    ### fit the classifier on the training features and labels\n",
    "    t0 = time()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    print(\"Training time  :\", round(time()-t0, 3), \"s\")\n",
    "    ### use the trained classifier to predict labels for the test features\n",
    "    t0 = time()\n",
    "    pred = clf.predict(features_test)\n",
    "    print(\"Predicting time:\", round(time()-t0, 3), \"s\")\n",
    "    ### calculate and return the accuracy on the test data\n",
    "    accuracy = accuracy_score(pred,labels_test)\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time  : 0.12 s\n",
      "Predicting time: 1.009 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88452787258248011"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBAccuracy(features_train, labels_train, features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
